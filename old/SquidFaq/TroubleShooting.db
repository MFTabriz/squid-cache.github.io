<?xml version="1.0" encoding="utf-8"?><!DOCTYPE article  PUBLIC '-//OASIS//DTD DocBook XML V4.4//EN'  'http://www.docbook.org/xml/4.4/docbookx.dtd'><article><articleinfo><title>SquidFaq/TroubleShooting</title><revhistory><revision><revnumber>32</revnumber><date>2015-09-03 20:12:49</date><authorinitials>Eliezer Croitoru</authorinitials><revremark>Addition of a suggestion for FreeBSD 10 tunings.</revremark></revision><revision><revnumber>31</revnumber><date>2013-09-05 08:08:40</date><authorinitials>AmosJeffries</authorinitials><revremark>mention that startup scripts can use ulimit or simiar and screw with FD expectations.</revremark></revision><revision><revnumber>30</revnumber><date>2011-11-23 00:17:46</date><authorinitials>AmosJeffries</authorinitials><revremark>some typos noticed by Martin Fuxa</revremark></revision><revision><revnumber>29</revnumber><date>2011-05-24 10:00:22</date><authorinitials>AmosJeffries</authorinitials><revremark>Linux requires ulimit -n option to be separate</revremark></revision><revision><revnumber>28</revnumber><date>2011-05-12 12:55:44</date><authorinitials>AmosJeffries</authorinitials><revremark>add auto-list for KnowledgeBase articles linked back to this Troubleshooting page.</revremark></revision><revision><revnumber>27</revnumber><date>2010-09-13 01:06:16</date><authorinitials>AmosJeffries</authorinitials><revremark>remove Solaris FD help. improved version in os-specific page. link to all os-specific pages with Troubleshooting help available.</revremark></revision><revision><revnumber>26</revnumber><date>2010-03-09 14:15:52</date><authorinitials>AmosJeffries</authorinitials><revremark>LInux info IS still relevant.</revremark></revision><revision><revnumber>25</revnumber><date>2010-02-22 12:20:36</date><authorinitials>FrancescoChemolli</authorinitials><revremark>Fixed dangling wiki-links</revremark></revision><revision><revnumber>24</revnumber><date>2010-02-19 13:30:01</date><authorinitials>FrancescoChemolli</authorinitials><revremark>Fixed dangling wiki-links</revremark></revision><revision><revnumber>23</revnumber><date>2010-02-19 13:25:25</date><authorinitials>FrancescoChemolli</authorinitials><revremark>Fixed dangling wiki-links</revremark></revision><revision><revnumber>22</revnumber><date>2009-09-22 11:46:07</date><authorinitials>AmosJeffries</authorinitials><revremark>shuffle the bug reporting and debug tracing info to its own page for easier references</revremark></revision><revision><revnumber>21</revnumber><date>2009-09-22 04:41:35</date><authorinitials>AmosJeffries</authorinitials><revremark>move more WindowsUpdate help to the WindowsUpdate page</revremark></revision><revision><revnumber>20</revnumber><date>2008-10-18 08:39:57</date><authorinitials>AmosJeffries</authorinitials><revremark>{!} should be (!)</revremark></revision><revision><revnumber>19</revnumber><date>2008-09-27 05:52:12</date><authorinitials>AmosJeffries</authorinitials><revremark>drop squid 1.x an &lt;2.5 info.</revremark></revision><revision><revnumber>18</revnumber><date>2008-09-19 03:19:39</date><authorinitials>AmosJeffries</authorinitials><revremark>update info for filedescriptors config on 2.7+</revremark></revision><revision><revnumber>17</revnumber><date>2008-08-27 12:09:20</date><authorinitials>AmosJeffries</authorinitials><revremark>add example of a usable backtrace - too many sets of memory locations being reported.</revremark></revision><revision><revnumber>16</revnumber><date>2008-07-03 22:31:06</date><authorinitials>Henrik Nordström</authorinitials></revision><revision><revnumber>15</revnumber><date>2008-06-24 10:08:34</date><authorinitials>AmosJeffries</authorinitials><revremark>document the differences in FD handling between Squid major versions</revremark></revision><revision><revnumber>14</revnumber><date>2008-05-18 19:38:59</date><authorinitials>localhost</authorinitials><revremark>converted to 1.6 markup</revremark></revision><revision><revnumber>13</revnumber><date>2008-04-01 08:50:49</date><authorinitials>Henrik Nordström</authorinitials><revremark>Kill obsolete section about https proxying</revremark></revision><revision><revnumber>12</revnumber><date>2008-02-07 20:06:32</date><authorinitials>kinkie</authorinitials><revremark>Updated chapter on NTLM authentication.</revremark></revision><revision><revnumber>11</revnumber><date>2007-11-19 22:11:00</date><authorinitials>ip03.plos.org</authorinitials></revision></revhistory></articleinfo><section><title>Starting Point</title><para>If your Squid version is older than 2.6 it is very outdated. Many of the issues experienced in those versions are now fixed in 2.6 and later. </para><para>Your first point of troubleshooting should be to test with a newer <emphasis>supported</emphasis> release and resolve any remaining issues with that install. </para><para>Current releases can be retrieved from <ulink url="http://www.squid-cache.org/Versions"/> or your operating system distributor. How to do this is outlined in the system-specific help pages. </para><para>Additional problems and resolutions for your specific system may be found in the system-specific help troubleshooting: <orderedlist><listitem><ulink url="https://wiki.squid-cache.org/SquidFaq/TroubleShooting/KnowledgeBase/CentOS"><emphasis role="strong">KnowledgeBase/</emphasis>CentOS</ulink></listitem><listitem><ulink url="https://wiki.squid-cache.org/SquidFaq/TroubleShooting/KnowledgeBase/Debian"><emphasis role="strong">KnowledgeBase/</emphasis>Debian</ulink></listitem><listitem><ulink url="https://wiki.squid-cache.org/SquidFaq/TroubleShooting/KnowledgeBase/Fedora"><emphasis role="strong">KnowledgeBase/</emphasis>Fedora</ulink></listitem><listitem><ulink url="https://wiki.squid-cache.org/SquidFaq/TroubleShooting/KnowledgeBase/Fink"><emphasis role="strong">KnowledgeBase/</emphasis>Fink</ulink></listitem><listitem><ulink url="https://wiki.squid-cache.org/SquidFaq/TroubleShooting/KnowledgeBase/Gentoo"><emphasis role="strong">KnowledgeBase/</emphasis>Gentoo</ulink></listitem><listitem><ulink url="https://wiki.squid-cache.org/SquidFaq/TroubleShooting/KnowledgeBase/Mandriva"><emphasis role="strong">KnowledgeBase/</emphasis>Mandriva</ulink></listitem><listitem><ulink url="https://wiki.squid-cache.org/SquidFaq/TroubleShooting/KnowledgeBase/NetBSD"><emphasis role="strong">KnowledgeBase/</emphasis>NetBSD</ulink></listitem><listitem><ulink url="https://wiki.squid-cache.org/SquidFaq/TroubleShooting/KnowledgeBase/OpenSUSE"><emphasis role="strong">KnowledgeBase/</emphasis>OpenSUSE</ulink></listitem><listitem><ulink url="https://wiki.squid-cache.org/SquidFaq/TroubleShooting/KnowledgeBase/RedHat"><emphasis role="strong">KnowledgeBase/</emphasis>RedHat</ulink></listitem><listitem><ulink url="https://wiki.squid-cache.org/SquidFaq/TroubleShooting/KnowledgeBase/SLES"><emphasis role="strong">KnowledgeBase/</emphasis>SLES</ulink></listitem><listitem><ulink url="https://wiki.squid-cache.org/SquidFaq/TroubleShooting/KnowledgeBase/Slackware"><emphasis role="strong">KnowledgeBase/</emphasis>Slackware</ulink></listitem><listitem><ulink url="https://wiki.squid-cache.org/SquidFaq/TroubleShooting/KnowledgeBase/Ubuntu"><emphasis role="strong">KnowledgeBase/</emphasis>Ubuntu</ulink></listitem></orderedlist><!--The macro FullSearch caused an error and should be blacklisted. It returned the data '

' which caused the docbook-formatter to choke. Please file a bug.--> </para><para>Some common situations have their own detailed explanations and workarounds: <orderedlist><listitem><ulink url="https://wiki.squid-cache.org/SquidFaq/TroubleShooting/KnowledgeBase/Hotmail"><emphasis role="strong">KnowledgeBase/</emphasis>Hotmail</ulink></listitem><listitem><ulink url="https://wiki.squid-cache.org/SquidFaq/TroubleShooting/KnowledgeBase/TransparentProxySelectiveBypass"><emphasis role="strong">KnowledgeBase/</emphasis>TransparentProxySelectiveBypass</ulink></listitem></orderedlist><!--The macro FullSearch caused an error and should be blacklisted. It returned the data '

' which caused the docbook-formatter to choke. Please file a bug.--> </para></section><section><title>Why am I getting &quot;Proxy Access Denied?&quot;</title><para>You may need to set up the <emphasis>http_access</emphasis> option to allow requests from your IP addresses.    Please see <ulink url="https://wiki.squid-cache.org/SquidFaq/TroubleShooting/SquidFaq/SquidAcl#">../SquidAcl</ulink> for information about that. </para><para>Alternately, you may have misconfigured one of your ACLs.  Check the <emphasis>access.log</emphasis> and <emphasis>squid.conf</emphasis> files for clues. </para></section><section><title>Connection Refused when reaching a sibling</title><para>I get <emphasis>Connection Refused</emphasis> when the cache tries to retrieve an object located on a sibling, even though the sibling thinks it delivered the object to my cache. </para><para>If the HTTP port number is wrong but the ICP port is correct you will send ICP queries correctly and the ICP replies will fool your cache into thinking the configuration is correct but large objects will fail since you don't have the correct HTTP port for the sibling in your <emphasis>squid.conf</emphasis> file.  If your sibling changed their <emphasis>http_port</emphasis>, you could have this problem for some time before noticing. </para></section><section><title>Running out of filedescriptors</title><para>If you see the <emphasis>Too many open files</emphasis> error message, you are most likely running out of file descriptors.  This may be due to running Squid on an operating system with a low filedescriptor limit.  This limit is often configurable in the kernel or with other system tuning tools.  There are two ways to run out of file descriptors:  first, you can hit the per-process limit on file descriptors.  Second, you can hit the system limit on total file descriptors for all processes. </para><informaltable><tgroup cols="2"><colspec colname="col_0"/><colspec colname="col_1"/><tbody><row rowsep="1"><entry colsep="1" rowsep="1"><para> <inlinemediaobject><imageobject><imagedata depth="16" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/icon-info.png" width="16"/></imageobject><textobject><phrase>{i}</phrase></textobject></inlinemediaobject> <inlinemediaobject><imageobject><imagedata depth="15" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/idea.png" width="15"/></imageobject><textobject><phrase>(!)</phrase></textobject></inlinemediaobject> </para></entry><entry colsep="1" rowsep="1"><para> Squid 2.0-2.6 provide a ./configure option --with-maxfd=N </para></entry></row><row rowsep="1"><entry colsep="1" rowsep="1"><para> <inlinemediaobject><imageobject><imagedata depth="16" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/icon-info.png" width="16"/></imageobject><textobject><phrase>{i}</phrase></textobject></inlinemediaobject> <inlinemediaobject><imageobject><imagedata depth="15" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/idea.png" width="15"/></imageobject><textobject><phrase>(!)</phrase></textobject></inlinemediaobject> </para></entry><entry colsep="1" rowsep="1"><para> Squid 2.7+ provide a squid.conf option max_filedescriptors </para></entry></row><row rowsep="1"><entry colsep="1" rowsep="1"><para> <inlinemediaobject><imageobject><imagedata depth="16" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/icon-info.png" width="16"/></imageobject><textobject><phrase>{i}</phrase></textobject></inlinemediaobject> <inlinemediaobject><imageobject><imagedata depth="15" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/idea.png" width="15"/></imageobject><textobject><phrase>(!)</phrase></textobject></inlinemediaobject> </para></entry><entry colsep="1" rowsep="1"><para> Squid 3.x provide a ./configure option --with-filedescriptors=N </para></entry></row></tbody></tgroup></informaltable><itemizedlist><listitem override="none"><para><inlinemediaobject><imageobject><imagedata depth="16" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/icon-error.png" width="16"/></imageobject><textobject><phrase>{X}</phrase></textobject></inlinemediaobject> Even with Squid built to support large numbers of FD and the system configuration default set to permit large numbers to be used. The ulimit or equivalent tools can change those limits under Squid at any time. Before reporting this as a problem or bug please carefully check your startup scripts and any tools used to run or manage Squid to discover if they are setting a low FD limit. </para></listitem></itemizedlist><section><title>Linux</title><para>Linux kernel 2.2.12 and later supports &quot;unlimited&quot; number of open files without patching. So does most of glibc-2.1.1 and later (all areas touched by Squid is safe from what I can tell, even more so in later glibc releases). But you still need to take some actions as the kernel defaults to only allow processes to use up to 1024 filedescriptors, and Squid picks up the limit at build time. </para><itemizedlist><listitem><para>Before configuring Squid run &quot;<emphasis>ulimit -HS -n ####</emphasis>&quot; (where #### is the number of filedescriptors you need to support). Be sure to run &quot;make clean&quot; before configure if you have already run configure as the script might otherwise have cached the prior result. </para></listitem><listitem><para>Configure, build and install Squid as usual </para></listitem><listitem><para>Make sure your script for starting Squid contains the above <emphasis>ulimit</emphasis> command to raise the filedescriptor limit. You may also need to allow a larger port span for outgoing connections (set in /proc/sys/net/ipv4/, like in &quot;<emphasis>echo 1024 32768 &gt; /proc/sys/net/ipv4/ip_local_port_range</emphasis>&quot;) </para><para><inlinemediaobject><imageobject><imagedata depth="15" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/alert.png" width="15"/></imageobject><textobject><phrase>/!\</phrase></textobject></inlinemediaobject> NOTE that the <emphasis role="strong">-n</emphasis> option is separate from the <emphasis role="strong">-HS</emphasis> options. ulimit will fail on some systems if you try to combine them. </para></listitem></itemizedlist><para>Alternatively you can </para><itemizedlist><listitem><para>Run configure with your needed configure options </para></listitem><listitem><para>edit include/autoconf.h and define SQUID_MAXFD to your desired limit. Make sure to make it a nice and clean modulo 64 value (multiple of 64) to avoid various bugs in the libc headers. </para></listitem><listitem><para>build and install Squid as usual </para></listitem><listitem><para>Set the runtime ulimit as described above when starting Squid. </para></listitem></itemizedlist><para>If running things as root is not an option then get your sysadmin to install a the needed ulimit command in /etc/inittscript (see man initscript), install a patched kernel where INR_OPEN in include/linux/fs.h is changed to at least the amount you need or have them install a small suid program which sets the limit (see link below). </para><para>More information can be found from Henriks <ulink url="http://squid.sourceforge.net/hno/linux-lfd.html">How to get many filedescriptors on Linux 2.2.X and later</ulink> page. </para></section><section><title>FreeBSD</title><section><title>2015</title><para><ulink url="https://wiki.squid-cache.org/SquidFaq/TroubleShooting/Eliezer%20Croitoru#">Eliezer Croitoru</ulink>: </para><para>* Referencing to <ulink url="https://www.freebsd.org/doc/handbook/configtuning-kernel-limits.html">Tuning Kernel Limits</ulink> of the FreeBSD based on Adrian Chad <ulink url="http://adrianchadd.blogspot.co.il/2013/08/why-oh-why-am-i-seeing-rst-frames-from.html">article</ulink>. </para><itemizedlist><listitem><para>The docs describes that the basic &quot;server accept&quot; socket is bounded to a queue of 128 connections. </para></listitem><listitem><para>You would probably see something like &quot;connection reset by peer&quot; and you will need to increase the <emphasis>kern.ipc.somaxconn</emphasis> to 2048 to match something useful for production network of about 300 users.  </para></listitem><listitem><para>In a case you have a loaded server you would need to increase it past the 16384 limit. </para></listitem></itemizedlist></section><section><title>older then 2015</title><itemizedlist><listitem override="none"><para><inlinemediaobject><imageobject><imagedata depth="15" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/devil.png" width="15"/></imageobject><textobject><phrase>&gt;:&gt;</phrase></textobject></inlinemediaobject> This information is outdated, and may no longer be relevant. </para></listitem></itemizedlist><para>by <ulink url="mailto:torsten.sturm@axis.de">Torsten Sturm</ulink> </para><itemizedlist><listitem><para>How do I check my maximum filedescriptors? </para><itemizedlist><listitem override="none"><para>Do <emphasis>sysctl -a</emphasis> and look for the value of <emphasis>kern.maxfilesperproc</emphasis>. </para></listitem></itemizedlist></listitem><listitem><para>How do I increase them? </para></listitem></itemizedlist><screen><![CDATA[sysctl -w kern.maxfiles=XXXX
sysctl -w kern.maxfilesperproc=XXXX]]></screen><informaltable><tgroup cols="2"><colspec colname="col_0"/><colspec colname="col_1"/><tbody><row rowsep="1"><entry colsep="1" rowsep="1"><para> <inlinemediaobject><imageobject><imagedata depth="15" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/alert.png" width="15"/></imageobject><textobject><phrase>/!\</phrase></textobject></inlinemediaobject> </para></entry><entry colsep="1" rowsep="1"><para>You probably want <emphasis>maxfiles &gt; maxfilesperproc</emphasis> if you're going to be pushing the limit. </para></entry></row></tbody></tgroup></informaltable><itemizedlist><listitem><para>What is the upper limit? </para><itemizedlist><listitem override="none"><para>I don't think there is a formal upper limit inside the kernel. All the data structures are dynamically allocated.  In practice there might be unintended metaphenomena (kernel spending too much time searching tables, for example). </para></listitem></itemizedlist></listitem></itemizedlist></section></section><section><title>General BSD</title><itemizedlist><listitem override="none"><para><inlinemediaobject><imageobject><imagedata depth="15" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/devil.png" width="15"/></imageobject><textobject><phrase>&gt;:&gt;</phrase></textobject></inlinemediaobject> This information is outdated, and may no longer be relevant. </para></listitem></itemizedlist><para>For most BSD-derived systems (SunOS, 4.4BSD, OpenBSD, FreeBSD, NetBSD, BSD/OS, 386BSD, Ultrix) you can also use the &quot;brute force&quot; method to increase these values in the kernel (requires a kernel rebuild): </para><itemizedlist><listitem><para>How do I check my maximum filedescriptors? </para><itemizedlist><listitem override="none"><para>Do <emphasis>pstat -T</emphasis> and look for the <emphasis>files</emphasis> value, typically expressed as the ratio of <emphasis>current</emphasis>maximum. </para></listitem></itemizedlist></listitem><listitem><para>How do I increase them the easy way? </para><itemizedlist><listitem override="none"><para>One way is to increase the value of the <emphasis>maxusers</emphasis> variable in the kernel configuration file and build a new kernel.  This method is quick and easy but also has the effect of increasing a wide variety of other variables that you may not need or want increased. </para></listitem></itemizedlist></listitem><listitem><para>Is there a more precise method? </para><itemizedlist><listitem override="none"><para>Another way is to find the <emphasis>param.c</emphasis> file in your kernel build area and change the arithmetic behind the relationship between <emphasis>maxusers</emphasis> and the maximum number of open files. </para></listitem></itemizedlist></listitem></itemizedlist><para>Here are a few examples which should lead you in the right direction: </para><section><title>SunOS</title><itemizedlist><listitem override="none"><para><inlinemediaobject><imageobject><imagedata depth="15" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/devil.png" width="15"/></imageobject><textobject><phrase>&gt;:&gt;</phrase></textobject></inlinemediaobject> This information is outdated, and may no longer be relevant. </para></listitem></itemizedlist><para>Change the value of <emphasis>nfile</emphasis> in <emphasis role="strong">'usr/kvm/sys/conf.common/param.c/tt&gt; by altering this equation: </emphasis> </para><screen/><para>Where <emphasis>NPROC</emphasis> is defined by: </para><screen><![CDATA[#define NPROC (10 + 16 * MAXUSERS)]]></screen></section><section><title>FreeBSD (from the 2.1.6 kernel)</title><itemizedlist><listitem override="none"><para><inlinemediaobject><imageobject><imagedata depth="15" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/devil.png" width="15"/></imageobject><textobject><phrase>&gt;:&gt;</phrase></textobject></inlinemediaobject> This information is outdated, and may no longer be relevant. </para></listitem></itemizedlist><para>Very similar to SunOS, edit <emphasis>/usr/src/sys/conf/param.c</emphasis> and alter the relationship between <emphasis>maxusers</emphasis> and the <emphasis>maxfiles</emphasis> and <emphasis>maxfilesperproc</emphasis> variables: </para><screen><![CDATA[int     maxfiles = NPROC*2;
int     maxfilesperproc = NPROC*2;]]></screen><para>Where <emphasis>NPROC</emphasis> is defined by: <emphasis>#define NPROC (20 + 16 * MAXUSERS)</emphasis> The per-process limit can also be adjusted directly in the kernel configuration file with the following directive: <emphasis>options OPEN_MAX=128</emphasis> </para></section><section><title>BSD/OS (from the 2.1 kernel)</title><itemizedlist><listitem override="none"><para><inlinemediaobject><imageobject><imagedata depth="15" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/devil.png" width="15"/></imageobject><textobject><phrase>&gt;:&gt;</phrase></textobject></inlinemediaobject> This information is outdated, and may no longer be relevant. </para></listitem></itemizedlist><para>Edit <emphasis>/usr/src/sys/conf/param.c</emphasis> and adjust the <emphasis>maxfiles</emphasis> math here: </para><screen><![CDATA[int     maxfiles = 3 * (NPROC + MAXUSERS) + 80;]]></screen><para>Where <emphasis>NPROC</emphasis> is defined by: <emphasis>#define NPROC (20 + 16 * MAXUSERS)</emphasis> You should also set the <emphasis>OPEN_MAX</emphasis> value in your kernel configuration file to change the per-process limit. </para></section></section><section><title>Reconfigure afterwards</title><itemizedlist><listitem override="none"><para><inlinemediaobject><imageobject><imagedata depth="15" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/devil.png" width="15"/></imageobject><textobject><phrase>&gt;:&gt;</phrase></textobject></inlinemediaobject> This information is outdated, and may no longer be relevant. </para></listitem></itemizedlist><para>After you rebuild/reconfigure your kernel with more filedescriptors, you must then recompile Squid.  Squid's configure script determines how many filedescriptors are available, so you must make sure the configure script runs again as well.  For example: </para><screen><![CDATA[cd squid-1.1.x
make realclean
./configure --prefix=/usr/local/squid
make]]></screen></section></section><section><title>What are these strange lines about removing objects?</title><para>For example: </para><screen><![CDATA[97/01/23 22:31:10| Removed 1 of 9 objects from bucket 3913
97/01/23 22:33:10| Removed 1 of 5 objects from bucket 4315
97/01/23 22:35:40| Removed 1 of 14 objects from bucket 6391]]></screen><para>These log entries are normal, and do not indicate that <emphasis>squid</emphasis> has reached <emphasis>cache_swap_high</emphasis>. </para><para>Consult your cache information page in <emphasis>cachemgr.cgi</emphasis> for a line like this: </para><screen><![CDATA[Storage LRU Expiration Age:     364.01 days]]></screen><para>Objects which have not been used for that amount of time are removed as a part of the regular maintenance.  You can set an upper limit on the <emphasis>LRU Expiration Age</emphasis> value with <emphasis>reference_age</emphasis> in the config file. </para></section><section><title>Can I change a Windows NT FTP server to list directories in Unix format?</title><para>Why, yes you can!  Select the following menus: </para><itemizedlist><listitem><para>Start </para></listitem><listitem><para>Programs </para></listitem><listitem><para>Microsoft Internet Server (Common) </para></listitem><listitem><para>Internet Service Manager </para></listitem></itemizedlist><para>This will bring up a box with icons for your various services. One of them should be a little ftp &quot;folder.&quot; Double click on this. </para><para>You will then have to select the server (there should only be one) Select that and then choose &quot;Properties&quot; from the menu and choose the &quot;directories&quot; tab along the top. </para><para>There will be an option at the bottom saying &quot;Directory listing style.&quot; Choose the &quot;Unix&quot; type, not the &quot;MS-DOS&quot; type. </para><para>by <emphasis>Oskar Pearson</emphasis> </para></section><section><title>Why am I getting &quot;Ignoring MISS from non-peer x.x.x.x?&quot;</title><para>You are receiving ICP MISSes (via UDP) from a parent or sibling cache whose IP address your cache does not know about.  This may happen in two situations. </para><para>If the peer is multihomed, it is sending packets out an interface which is not advertised in the DNS.  Unfortunately, this is a configuration problem at the peer site.  You can tell them to either add the IP address interface to their DNS, or use Squid's &quot;udp_outgoing_address&quot; option to force the replies out a specific interface.  For example: <emphasis>on your parent squid.conf:</emphasis> </para><screen><![CDATA[udp_outgoing_address proxy.parent.com]]></screen><para><emphasis>on your squid.conf:</emphasis> </para><screen><![CDATA[cache_peer proxy.parent.com parent 3128 3130]]></screen><para>You can also see this warning when sending ICP queries to multicast addresses.  For security reasons, Squid requires your configuration to list all other caches listening on the multicast group address.  If an unknown cache listens to that address and sends replies, your cache will log the warning message.  To fix this situation, either tell the unknown cache to stop listening on the multicast address, or if they are legitimate, add them to your configuration file. </para></section><section><title>DNS lookups for domain names with underscores (_) always fail.</title><para>The standards for naming hosts ( <ulink url="ftp://ftp.isi.edu/in-notes/rfc952.txt">RFC 952</ulink> and <ulink url="ftp://ftp.isi.edu/in-notes/rfc1101.txt">RFC 1101</ulink>) do not allow underscores in domain names: </para><screen><![CDATA[A "name" (Net, Host, Gateway, or Domain name) is a text string up to 24 characters drawn from the alphabet (A-Z), digits (0-9), minus sign (-), and period (.).]]></screen><para>The resolver library that ships with recent versions of BIND enforces this restriction, returning an error for any host with underscore in the hostname.  The best solution is to complain to the hostmaster of the offending site, and ask them to rename their host. </para><para>See also the <ulink url="http://www.intac.com/~cdp/cptd-faq/section4.html#underscore">comp.protocols.tcp-ip.domains FAQ</ulink>. </para><para>Some people have noticed that <ulink url="ftp://ftp.isi.edu/in-notes/rfc1033.txt">RFC 1033</ulink> implies that underscores <emphasis role="underline">are</emphasis> allowed.  However, this is an <emphasis role="underline">informational</emphasis> RFC with a poorly chosen example, and not a <emphasis role="underline">standard</emphasis> by any means. </para></section><section><title>Why does Squid say: &quot;Illegal character in hostname; underscores are not allowed?'</title><para>See the above question.  The underscore character is not valid for hostnames. </para><para>Some DNS resolvers allow the underscore, so yes, the hostname might work fine when you don't use Squid. </para><para>To make Squid allow underscores in hostnames: </para><itemizedlist><listitem override="none"><informaltable><tgroup cols="3"><colspec colname="col_0"/><colspec colname="col_1"/><colspec colname="col_2"/><tbody><row rowsep="1"><entry colsep="1" rowsep="1"><para> <inlinemediaobject><imageobject><imagedata depth="16" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/icon-info.png" width="16"/></imageobject><textobject><phrase>{i}</phrase></textobject></inlinemediaobject> </para></entry><entry colsep="1" rowsep="1"><para> Squid 2.x </para></entry><entry colsep="1" rowsep="1"><para> Re-build with <emphasis role="strong">--enable-underscores</emphasis> configure option </para></entry></row><row rowsep="1"><entry colsep="1" rowsep="1"><para> <inlinemediaobject><imageobject><imagedata depth="16" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/icon-info.png" width="16"/></imageobject><textobject><phrase>{i}</phrase></textobject></inlinemediaobject> </para></entry><entry colsep="1" rowsep="1"><para> Squid-3.x </para></entry><entry colsep="1" rowsep="1"><para> add to squid.conf: <emphasis role="strong">enable_underscores on</emphasis> </para></entry></row></tbody></tgroup></informaltable></listitem></itemizedlist></section><section><title>Why am I getting access denied from a sibling cache?</title><para>The answer to this is somewhat complicated, so please hold on. </para><itemizedlist><listitem override="none"><informaltable><tgroup cols="2"><colspec colname="col_0"/><colspec colname="col_1"/><tbody><row rowsep="1"><entry colsep="1" rowsep="1"><para> <inlinemediaobject><imageobject><imagedata depth="16" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/icon-info.png" width="16"/></imageobject><textobject><phrase>{i}</phrase></textobject></inlinemediaobject> </para></entry><entry colsep="1" rowsep="1"><para> Most of this text is taken from <ulink url="http://www.life-gone-hazy.com/writings/icp-squid.ps.gz">ICP and the Squid Web Cache</ulink> </para></entry></row></tbody></tgroup></informaltable></listitem></itemizedlist><para>An ICP query does not include any parent or sibling designation, so the receiver really has no indication of how the peer cache is configured to use it.  This issue becomes important when a cache is willing to serve cache hits to anyone, but only handle cache misses for its paying users or customers.  In other words, whether or not to allow the request depends on if the result is a hit or a miss.  To accomplish this, Squid acquired the <emphasis>miss_access</emphasis> feature in October of 1996. </para><para>The necessity of &quot;miss access&quot; makes life a little bit complicated, and not only because it was awkward to implement.  Miss access means that the ICP query reply must be an extremely accurate prediction of the result of a subsequent HTTP request.  Ascertaining this result is actually very hard, if not impossible to do, since the ICP request cannot convey the full HTTP request. Additionally, there are more types of HTTP request results than there are for ICP.  The ICP query reply will either be a hit or miss. However, the HTTP request might result in a &quot;<emphasis>304 Not Modified</emphasis>&quot; reply sent from the origin server.  Such a reply is not strictly a hit since the peer needed to forward a conditional request to the source.  At the same time, its not strictly a miss either since the local object data is still valid, and the Not-Modified reply is quite small. </para><para>One serious problem for cache hierarchies is mismatched freshness parameters.  Consider a cache <emphasis>C</emphasis> using &quot;strict&quot; freshness parameters so its users get maximally current data. <emphasis>C</emphasis> has a sibling <emphasis>S</emphasis> with less strict freshness parameters. When an object is requested at <emphasis>C</emphasis>, <emphasis>C</emphasis> might find that <emphasis>S</emphasis> already has the object via an ICP query and ICP HIT response.  <emphasis>C</emphasis> then retrieves the object from <emphasis>S</emphasis>. </para><para>In an HTTP/1.0 world, <emphasis>C</emphasis> (and <emphasis>Cs client) will receive an object that was never subject to its local freshness rules.  Neither HTTP/1.0 nor ICP provides any way to ask only for objects less than a certain age.  If the retrieved object is stale by </emphasis>C<emphasis>s rules, it will be removed from </emphasis>C<emphasis>s cache, but it will subsequently be fetched from </emphasis>S<emphasis> so long as it remains fresh there.  This configuration miscoupling problem is a significant deterrent to establishing both parent and sibling relationships. </emphasis> </para><para><emphasis>HTTP/1.1 provides numerous request headers to specify freshness requirements, which actually introduces a different problem for cache hierarchies:  ICP still does not include any age information, neither in query nor reply.  So </emphasis>S<emphasis> may return an ICP HIT if its copy of the object is fresh by its configuration parameters, but the subsequent HTTP request may result in a cache miss due to any </emphasis>Cache-control:<emphasis> headers originated by </emphasis>C<emphasis> or by </emphasis>C<emphasis> 's client.  Situations now emerge where the ICP reply no longer matches the HTTP request result. </emphasis> </para><para><emphasis>In the end, the fundamental problem is that the ICP query does not provide enough information to accurately predict whether the HTTP request will be a hit or miss.   In fact, the current ICP Internet Draft is very vague on this subject.  What does ICP HIT really mean?  Does it mean &quot;I know a little about that URL and have some copy of the object?&quot;  Or does it mean &quot;I have a valid copy of that object and you are allowed to get it from me?&quot; </emphasis> </para><para><emphasis>So, what can be done about this problem?  We really need to change ICP so that freshness parameters are included.  Until that happens, the members of a cache hierarchy have only two options to totally eliminate the &quot;access denied&quot; messages from sibling caches: </emphasis> </para><itemizedlist><listitem><para><emphasis>Make sure all members have the same </emphasis>refresh_rules<emphasis> parameters. </emphasis> </para></listitem><listitem><para>Do not use miss_access<emphasis> at all.  Promise your sibling cache administrator that </emphasis>your<emphasis> cache is properly configured and that you will not abuse their generosity.  The sibling cache administrator can check his log files to make sure you are keeping your word. </emphasis> </para></listitem></itemizedlist><para>If neither of these is realistic, then the sibling relationship should not exist. </para></section><section><title>Cannot bind socket FD NN to *:8080 (125) Address already in use</title><para>This means that another processes is already listening on port 8080 (or whatever you're using).  It could mean that you have a Squid process already running, or it could be from another program.  To verify, use the <emphasis>netstat</emphasis> command: </para><screen><![CDATA[netstat -antup | grep 8080]]></screen><itemizedlist><listitem override="none"><para><inlinemediaobject><imageobject><imagedata depth="16" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/icon-info.png" width="16"/></imageobject><textobject><phrase>{i}</phrase></textobject></inlinemediaobject> <inlinemediaobject><imageobject><imagedata depth="15" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/idea.png" width="15"/></imageobject><textobject><phrase>(!)</phrase></textobject></inlinemediaobject>  Windows Users need to use <emphasis>netstat -ant</emphasis> and manually find the entry. </para></listitem></itemizedlist><para>If you find that some process has bound to your port, but you're not sure which process it is, you might be able to use the excellent <ulink url="ftp://vic.cc.purdue.edu/pub/tools/unix/lsof/">lsof</ulink> program.  It will show you which processes own every open file descriptor on your system. </para></section><section><title>icpDetectClientClose: ERROR xxx.xxx.xxx.xxx: (32) Broken pipe</title><para>This means that the client socket was closed by the client before Squid was finished sending data to it.  Squid detects this by trying to read(2)<emphasis> some data from the socket.  If the </emphasis>read(2)<emphasis> call fails, then Squid konws the socket has been closed.   Normally the </emphasis>read(2)<emphasis> call returns </emphasis>ECONNRESET: Connection reset by peer<emphasis> and these are NOT logged.  Any other error messages (such as </emphasis>EPIPE: Broken pipe<emphasis> are logged to </emphasis>cache.log<emphasis>.  See the &quot;intro&quot; of section 2 of your Unix manual for a list of all error codes. </emphasis> </para></section><section><title>icpDetectClientClose: FD 135, 255 unexpected bytes</title><para>These are caused by misbehaving Web clients attempting to use persistent connections. </para></section><section><title>Does Squid work with NTLM Authentication?</title><para>Yes, Squid supports Microsoft NTLM authentication to authenticate users accessing the proxy server itself (be it in a forward or reverse setup). See <ulink url="https://wiki.squid-cache.org/SquidFaq/TroubleShooting/SquidFaq/ProxyAuthentication#">../ProxyAuthentication</ulink> for further details </para><para>Squid 2.6+ and 3.1+ also support the kind of infrastructure that's needed to properly allow an user to authenticate against an NTLM-enabled webserver. </para><para>As NTLM authentication backends go, the real work is usually done by <ulink url="http://www.samba.org/">Samba</ulink> on squid's behalf. That being the case, Squid supports any authentication backend supported by Samba, including Samba itself and MS Windows 3.51 and onwards Domain Controllers. </para><para>NTLM for HTTP is, however, an horrible example of an authentication protocol, and we recommend to avoid using it in favour of saner and standard-sanctioned alternatives such as Digest. </para></section><section><title>My Squid becomes very slow after it has been running for some time.</title><para>This is most likely because Squid is using more memory than it should be for your system.  When the Squid process becomes large, it experiences a lot of paging.  This will very rapidly degrade the performance of Squid. Memory usage is a complicated problem.  There are a number of things to consider. </para></section><section><title>WARNING: Failed to start 'dnsserver'</title><itemizedlist><listitem override="none"><para><inlinemediaobject><imageobject><imagedata depth="16" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/icon-info.png" width="16"/></imageobject><textobject><phrase>{i}</phrase></textobject></inlinemediaobject> <inlinemediaobject><imageobject><imagedata depth="15" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/idea.png" width="15"/></imageobject><textobject><phrase>(!)</phrase></textobject></inlinemediaobject> All current Squid now contain an optimized internal DNS engine. Which is much faster and responsive that then the dnsserver helper. That should be used by preference. </para></listitem></itemizedlist><para>This could be a permission problem.  Does the Squid userid have permission to execute the dnsserver<emphasis> program? </emphasis> </para></section><section><title>Sending bug reports to the Squid team</title><para>see <ulink url="https://wiki.squid-cache.org/SquidFaq/TroubleShooting/SquidFaq/BugReporting#">SquidFaq/BugReporting</ulink> </para></section><section><title>FATAL: ipcache_init: DNS name lookup tests failed</title><itemizedlist><listitem override="none"><para><inlinemediaobject><imageobject><imagedata depth="16" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/icon-info.png" width="16"/></imageobject><textobject><phrase>{i}</phrase></textobject></inlinemediaobject> <inlinemediaobject><imageobject><imagedata depth="15" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/idea.png" width="15"/></imageobject><textobject><phrase>(!)</phrase></textobject></inlinemediaobject> This issue is now permanently resolved in Squid 3.1 and later. </para></listitem></itemizedlist><para>Squid normally tests your system's DNS configuration before it starts server requests.  Squid tries to resolve some common DNS names, as defined in the dns_testnames<emphasis> configuration directive.  If Squid cannot resolve these names, it could mean: </emphasis> </para><itemizedlist><listitem><para>your DNS nameserver is unreachable or not running. </para></listitem><listitem><para>your System is in the process of booting </para></listitem><listitem><para>your /etc/resolv.conf file may contain incorrect information. </para></listitem><listitem><para>your /etc/resolv.conf file may have incorrect permissions, and may be unreadable by Squid. </para></listitem></itemizedlist><para>To disable this feature, use the <emphasis role="strong">-D</emphasis> command line option. Due to this issue displaying on Boot. Is is highly recommended that OS startup scripts for Squid earlier than 3.1 use this option to disable tests. </para><para><emphasis>Note, Squid does NOT use the </emphasis>dnsservers<emphasis> to test the DNS.  The test is performed internally, before the </emphasis>dnsservers<emphasis> start. ' </emphasis></para></section><section><title>FATAL: Failed to make swap directory /var/spool/cache: (13) Permission denied</title><para>Starting with version 1.1.15, we have required that you first run </para><screen><![CDATA[squid -z]]></screen><para>to create the swap directories on your filesystem. </para><para>Squid basic default is user <emphasis role="strong">nobody</emphasis>. This can be overridden in packages with the <emphasis role="strong">--with-default-user</emphasis> option when building or in squid.conf with the <emphasis role="strong">cache_effective_user</emphasis> option. </para><para>The Squid process takes on the given userid before making the directories. If the </para>cache_dir<emphasis> directory (e.g. /var/spool/cache) does not exist, and the Squid userid does not have permission to create it, then you will get the &quot;permission denied&quot; error.  This can be simply fixed by manually creating the cache directory. <para>Alternatively, if the directory already exists, then your operating system may be returning &quot;Permission Denied&quot; instead of &quot;File Exists&quot; on the mkdir() system call. </para></emphasis></section><section><title>FATAL: Cannot open HTTP Port</title><para>Either </para><orderedlist numeration="arabic"><listitem><para>the Squid userid does not have permission to bind to the port, or </para></listitem><listitem><para>some other process has bound itself to the port </para><para><inlinemediaobject><imageobject><imagedata depth="16" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/icon-info.png" width="16"/></imageobject><textobject><phrase>{i}</phrase></textobject></inlinemediaobject> Remember that root privileges are required to open port numbers less than 1024.  If you see this message when using a high port number, or even when starting Squid as root, then the port has already been opened by another process. </para><para><inlinemediaobject><imageobject><imagedata depth="16" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/icon-info.png" width="16"/></imageobject><textobject><phrase>{i}</phrase></textobject></inlinemediaobject> SELinux can also deny squid access to port 80, even if you are starting squid as root. Configure SELinux to allow squid to open port 80 or disable SELinux in this case. </para><para><inlinemediaobject><imageobject><imagedata depth="16" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/icon-info.png" width="16"/></imageobject><textobject><phrase>{i}</phrase></textobject></inlinemediaobject> Maybe you are running in the HTTP Accelerator mode and there is already a HTTP server running on port 80?  If you're really stuck, install the way cool <ulink url="ftp://vic.cc.purdue.edu/pub/tools/unix/lsof/">lsof</ulink> utility to show you which process has your port in use. </para></listitem></orderedlist></section><section><title>FATAL: All redirectors have exited!</title><para>This is explained in Features/Redirectors. </para></section><section><title>FATAL: Cannot open /usr/local/squid/logs/access.log: (13) Permission denied</title><para>In Unix, things like </para>processes<emphasis> and </emphasis>files<emphasis> have an </emphasis>owner<emphasis>. For Squid, the process owner and file owner should be the same.  If they are not the same, you may get messages like &quot;permission denied.&quot; <para>To find out who owns a file, use the command: </para><screen><![CDATA[ls -l]]></screen><para>A process is normally owned by the user who starts it.  However, Unix sometimes allows a process to change its owner.  If you specified a value for the </para>cache_effective_user<emphasis> option in </emphasis>squid.conf<emphasis>, then that will be the process owner. The files must be owned by this same userid. <para>If all this is confusing, then you probably should not be running Squid until you learn some more about Unix. As a reference, I suggest <ulink url="http://www.oreilly.com/catalog/lunix4/">Learning the UNIX Operating System, 4th Edition</ulink>. </para></emphasis></emphasis></section><section><title>pingerOpen: icmp_sock: (13) Permission denied</title><para>This means your </para>pinger<emphasis> helper program does not have root priveleges. <para>You should either do this when building Squid: </para><screen><![CDATA[make install pinger]]></screen><para>or </para><screen><![CDATA[# chown root /usr/local/squid/bin/pinger
# chmod 4755 /usr/local/squid/bin/pinger]]></screen><itemizedlist><listitem override="none"><para><inlinemediaobject><imageobject><imagedata depth="16" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/icon-info.png" width="16"/></imageobject><textobject><phrase>{i}</phrase></textobject></inlinemediaobject> <inlinemediaobject><imageobject><imagedata depth="15" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/idea.png" width="15"/></imageobject><textobject><phrase>(!)</phrase></textobject></inlinemediaobject> location of the pinger binary may vary. I recommend searching for it first: </para></listitem></itemizedlist><screen><![CDATA[locate bin/pinger]]></screen></emphasis></section><section><title>What is a forwarding loop?</title><para>A forwarding loop is when a request passes through one proxy more than once.  You can get a forwarding loop if </para><itemizedlist><listitem><para>a cache forwards requests to itself.  This might happen with interception caching (or server acceleration) configurations. </para></listitem><listitem><para>a pair or group of caches forward requests to each other.  This can happen when Squid uses ICP, Cache Digests, or the ICMP RTT database to select a next-hop cache. </para></listitem></itemizedlist><para>Forwarding loops are detected by examining the Via</para> request header. Each cache which &quot;touches&quot; a request must add its hostname to the <emphasis>Via</emphasis> header.  If a cache notices its own hostname in this header for an incoming request, it knows there is a forwarding loop somewhere. <itemizedlist><listitem override="none"><para><inlinemediaobject><imageobject><imagedata depth="15" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/alert.png" width="15"/></imageobject><textobject><phrase>/!\</phrase></textobject></inlinemediaobject> Squid may report a forwarding loop if a request goes through two caches that have the same <emphasis role="strong">visible_hostname</emphasis> value. If you want to have multiple machines with the same <emphasis role="strong">visible_hostname</emphasis> then you must give each machine a different <emphasis role="strong">unique_hostname</emphasis> so that forwarding loops are correctly detected. </para></listitem></itemizedlist><para>When Squid detects a forwarding loop, it is logged to the <emphasis>cache.log</emphasis> file with the recieved <emphasis>Via</emphasis> header.  From this header you can determine which cache (the last in the list) forwarded the request to you. </para><itemizedlist><listitem override="none"><para><inlinemediaobject><imageobject><imagedata depth="15" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/idea.png" width="15"/></imageobject><textobject><phrase>(!)</phrase></textobject></inlinemediaobject> One way to reduce forwarding loops is to change a <emphasis>parent</emphasis> relationship to a <emphasis>sibling</emphasis> relationship. </para><para><inlinemediaobject><imageobject><imagedata depth="15" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/idea.png" width="15"/></imageobject><textobject><phrase>(!)</phrase></textobject></inlinemediaobject> Another way is to use <emphasis>cache_peer_access</emphasis> rules. </para></listitem></itemizedlist></section><section><title>accept failure: (71) Protocol error</title><para>This error message is seen mostly on Solaris systems. <ulink url="mailto:mtk@ny.ubs.com">Mark Kennedy</ulink> gives a great explanation: </para><screen><![CDATA[Error 71 [EPROTO] is an obscure way of reporting that clients made it onto your
server's TCP incoming connection queue but the client tore down the
connection before the server could accept it.  I.e.  your server ignored
its clients for too long.  We've seen this happen when we ran out of
file descriptors.  I guess it could also happen if something made squid
block for a long time.]]></screen></section><section><title>storeSwapInFileOpened: ... Size mismatch</title><informaltable><tgroup cols="2"><colspec colname="col_0"/><colspec colname="col_1"/><tbody><row rowsep="1"><entry colsep="1" rowsep="1"><para> <inlinemediaobject><imageobject><imagedata depth="16" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/icon-info.png" width="16"/></imageobject><textobject><phrase>{i}</phrase></textobject></inlinemediaobject> </para></entry><entry colsep="1" rowsep="1"><para> These messages are specific to squid 2.x </para></entry></row></tbody></tgroup></informaltable><para>Got these messages in my cache.log - I guess it means that the index contents do not match the contents on disk. </para><para>What does Squid do in this case? </para><para>These happen when Squid reads an object from disk for a cache hit.  After it opens the file, Squid checks to see if the size is what it expects it should be.  If the size doesn't match, the error is printed.  In this case, Squid does not send the wrong object to the client.  It will re-fetch the object from the source. </para></section><section><title>Why do I get ''fwdDispatch: Cannot retrieve 'https://www.buy.com/corp/ordertracking.asp' ''</title><para>These messages are caused by buggy clients, mostly Netscape Navigator. What happens is, Netscape sends an HTTPS/SSL request over a persistent HTTP connection. Normally, when Squid gets an SSL request, it looks like this: </para><screen><![CDATA[CONNECT www.buy.com:443 HTTP/1.0]]></screen><para>Then Squid opens a TCP connection to the destination host and port, and the <emphasis>real</emphasis> request is sent encrypted over this connection.  Thats the whole point of SSL, that all of the information must be sent encrypted. </para><para>With this client bug, however, Squid receives a request like this: </para><screen><![CDATA[CONNECT https://www.buy.com/corp/ordertracking.asp HTTP/1.0]]></screen><para>Now, all of the headers, and the message body have been sent, <emphasis>unencrypted</emphasis> to Squid.  There is no way for Squid to somehow turn this into an SSL request. The only thing we can do is return the error message. <itemizedlist><listitem override="none"><para><inlinemediaobject><imageobject><imagedata depth="15" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/attention.png" width="15"/></imageobject><textobject><phrase>&lt;!&gt;</phrase></textobject></inlinemediaobject> <inlinemediaobject><imageobject><imagedata depth="15" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/idea.png" width="15"/></imageobject><textobject><phrase>(!)</phrase></textobject></inlinemediaobject> This browser bug does represent a <emphasis role="strong">security risk</emphasis> because the browser is sending sensitive information unencrypted over the network. </para></listitem></itemizedlist></para></section><section><title>Squid can't access URLs like http://3626046468/ab2/cybercards/moreinfo.html</title><para>by Dave J Woolley (DJW at bts dot co dot uk) </para><itemizedlist><listitem override="none"><para><inlinemediaobject><imageobject><imagedata depth="15" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/idea.png" width="15"/></imageobject><textobject><phrase>(!)</phrase></textobject></inlinemediaobject> These are illegal URLs, generally only used by illegal sites; typically the web site that supports a spammer and is expected to survive a few hours longer than the spamming account. </para></listitem></itemizedlist><para>Their intention is to: </para><itemizedlist><listitem><para>confuse content filtering rules on proxies, and possibly some browsers' idea of whether they are trusted sites on the local intranet; </para></listitem><listitem><para>confuse whois (?); </para></listitem><listitem><para>make people think they are not IP addresses and unknown domain names, in an attempt to stop them trying to locate and complain to the ISP. </para></listitem></itemizedlist><para>Any browser or proxy that works with them should be considered a security risk. </para><para><ulink url="http://www.ietf.org/rfc/rfc1738.txt">RFC 1738</ulink> has this to say about the hostname part of a URL: </para><screen><![CDATA[The fully qualified domain name of a network host, or its IP
address as a set of four decimal digit groups separated by
".". Fully qualified domain names take the form as described
in Section 3.5 of RFC 1034 [13] and Section 2.1 of RFC 1123
[5]: a sequence of domain labels separated by ".", each domain
label starting and ending with an alphanumerical character and
possibly also containing "-" characters. The rightmost domain
label will never start with a digit, though, which
syntactically distinguishes all domain names from the IP
addresses.]]></screen></section><section><title>I get a lot of &quot;URI has whitespace&quot; error messages in my cache log, what should I do?</title><itemizedlist><listitem override="none"><para><inlinemediaobject><imageobject><imagedata depth="15" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/idea.png" width="15"/></imageobject><textobject><phrase>(!)</phrase></textobject></inlinemediaobject> Whitespace characters (space, tab, newline, carriage return) are not allowed in URI's and URL's. </para></listitem></itemizedlist><para>Unfortunately, a number of web services generate URL's with whitespace.  Of course your favorite browser silently accomodates these bad URL's.  The servers (or people) that generate these URL's are in violation of Internet standards.  The whitespace characters should be encoded. </para><para>If you want Squid to accept URL's with whitespace, you have to decide how to handle them.  There are four choices that you can set with the </para>uri_whitespace<emphasis> option in squid.conf: <itemizedlist><listitem><para>STRIP </para><itemizedlist><listitem override="none"><para> </para><inlinemediaobject><imageobject><imagedata depth="15" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/idea.png" width="15"/></imageobject><textobject><phrase>(!)</phrase></textobject></inlinemediaobject><para> This is the correct way to handle them. This is the default for Squid 3.x. </para><para/></listitem></itemizedlist></listitem><listitem><para>DENY </para><itemizedlist><listitem override="none"><para> </para><inlinemediaobject><imageobject><imagedata depth="15" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/idea.png" width="15"/></imageobject><textobject><phrase>(!)</phrase></textobject></inlinemediaobject><para> The request is denied with an &quot;Invalid Request&quot; message. This is the default for Squid2.x. </para><para/></listitem></itemizedlist></listitem><listitem><para>ALLOW </para><itemizedlist><listitem override="none"><para>The request is allowed and the URL remains unchanged. </para></listitem></itemizedlist></listitem><listitem><para>ENCODE </para><itemizedlist><listitem override="none"><para>The whitespace characters are encoded according to </para><ulink url="http://www.ietf.org/rfc/rfc1738.txt">RFC 1738</ulink><para>.</para><para/></listitem></itemizedlist></listitem><listitem><para>CHOP </para><itemizedlist><listitem override="none"><para>The URL is chopped at the first whitespace character and then processed normally.</para></listitem></itemizedlist></listitem></itemizedlist><para>Only STRIP and DENY are the only approved ways of handling these URI. Others are technically violations and should not be performed. The broken web service should be fixed instead. It is breaking much more of the Internet than just your proxy. </para></emphasis></section><section><title>commBind: Cannot bind socket FD 5 to 127.0.0.1:0: (49) Can't assign requested address</title><para>This likely means that your system does not have a loopback network device, or that device is not properly configured. All Unix systems should have a network device named lo0</para>, and it should be configured with the address 127.0.0.1.  If not, you may get the above error message. To check your system, run: <screen><![CDATA[ifconfig]]></screen><itemizedlist><listitem override="none"><para><inlinemediaobject><imageobject><imagedata depth="16" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/icon-info.png" width="16"/></imageobject><textobject><phrase>{i}</phrase></textobject></inlinemediaobject> Windows users must use: <emphasis role="strong">ipfconfig</emphasis> </para></listitem></itemizedlist><para>The result should contain: </para><screen><![CDATA[lo        Link encap:Local Loopback  
          inet addr:127.0.0.1  Mask:255.0.0.0
          inet6 addr: ::1/128 Scope:Host]]></screen><para>If you use FreeBSD, see </para>freebsd-no-lo0</section><section><title>What does &quot;sslReadClient: FD 14: read failure: (104) Connection reset by peer&quot; mean?</title><para>&quot;Connection reset by peer&quot; is an error code that Unix operating systems sometimes return for read</para>, <emphasis>write</emphasis>, <emphasis>connect</emphasis>, and other system calls. <para/>Connection reset means that the other host, the peer, sent us a RESET packet on a TCP connection.  A host sends a RESET when it receives an unexpected packet for a nonexistent connection.  For example, if one side sends data at the same time that the other side closes a connection, when the other side receives the data it may send a reset back. <para/>The fact that these messages appear in Squid's log might indicate a problem, such as a broken origin server or parent cache.  On the other hand, they might be &quot;normal,&quot; especially since some applications are known to force connection resets rather than a proper close. <para/>You probably don't need to worry about them, unless you receive a lot of user complaints relating to SSL sites. <para/>Rick Jones notes that if the server is running a Microsoft TCP stack, clients receive RST segments whenever the listen queue overflows.  In other words, if the server is really busy, new connections receive the reset message. This is contrary to rational behaviour, but is unlikely to change. </section><section><title>What does ''Connection refused'' mean?</title><para>This is an error message, generated by your operating system, in response to a connect() system call.  It happens when there is no server at the other end listening on the port number that we tried to connect to. </para><para>It is quite easy to generate this error on your own. Simply telnet to a random, high numbered port: </para><screen><![CDATA[telnet 12345]]></screen><para>It happens because there is no server listening for connections on port 12345. </para><para>When you see this in response to a URL request, it probably means the origin server web site is temporarily down.  It may also mean that your parent cache is down, if you have one. </para></section><section><title>squid: ERROR: no running copy</title><para>You may get this message when you run commands like <emphasis role="strong">squid -k rotate</emphasis>. </para><para>This error message usually means that the </para>squid.pid<emphasis> file is missing.  Since the PID file is normally present when squid is running, the absence of the PID file usually means Squid is not running. If you accidentally delete the PID file, Squid will continue running, and you won't be able to send it any signals. </emphasis> <itemizedlist><listitem override="none"><para><inlinemediaobject><imageobject><imagedata depth="16" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/icon-info.png" width="16"/></imageobject><textobject><phrase>{i}</phrase></textobject></inlinemediaobject> If you accidentally removed the PID file, there are two ways to get it back. </para></listitem></itemizedlist><para>First locate the proces ID by running <emphasis>ps</emphasis> and find Squid. You'll probably see two processes, like this: </para><screen><![CDATA[% ps ax | grep squid
]]><![CDATA[
  PID TTY      STAT   TIME COMMAND
 2267 ?        Ss     0:00 /usr/sbin/squid-ipv6 -D -sYC
 2735 pts/0    S+     0:00 grep squid
 8893 ?        Rl     2:57 (squid) -D -sYC
 8894 ?        Ss     0:17 /bin/bash /etc/squid3/helper/redirector.sh]]></screen><para>You want the <emphasis role="strong">(squid)</emphasis> process id, 8893 in this case. </para><para>The first solution is to create the PID file yourself and put the process id number there. For example: </para><screen><![CDATA[echo 8893 > /usr/local/squid/logs/squid.pid]]></screen><itemizedlist><listitem override="none"><para><inlinemediaobject><imageobject><imagedata depth="15" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/alert.png" width="15"/></imageobject><textobject><phrase>/!\</phrase></textobject></inlinemediaobject> Be careful of file permissions. It's no use having a .pid file if squid can't update it when things change. </para></listitem></itemizedlist><para>The second is to use the above technique to find the Squid process id. Then to send the process a HUP signal, which is the same as <emphasis>squid -k reconfigure</emphasis>: </para><screen><![CDATA[kill -SIGHUP 8893]]></screen><para>The reconfigure process creates a new PID file automatically. </para></section><section><title>FATAL: getgrnam failed to find groupid for effective group 'nogroup'</title><para>You are probably starting Squid as root.  Squid is trying to find a group-id that doesn't have any special priveleges that it will run as.  The default is <emphasis role="strong">nogroup</emphasis>, but this may not be defined on your system. </para><para>The best fix for this is to assign squid a low-privilege user-id and assign that uerid to a group-id. There is a good chance that <emphasis>nobody</emphasis> will work for you as part of group <emphasis>nogroup</emphasis>. </para><para>Alternatively in older Squid the <emphasis>cache_effective_group</emphasis> in squid.conf my be changed to the name of an unpriveledged group from <emphasis>/etc/group</emphasis>.  There is a good chance that <emphasis>nobody</emphasis> will work for you. </para></section><section><title>Squid uses 100% CPU</title><para>There may be many causes for this. </para><para>Andrew Doroshenko reports that removing <emphasis>/dev/null</emphasis>, or mounting a filesystem with the <emphasis>nodev</emphasis> option, can cause Squid to use 100% of CPU.  His suggested solution is to &quot;touch /dev/null.&quot; </para></section><section><title>Webmin's ''cachemgr.cgi'' crashes the operating system</title><para>Mikael Andersson reports that clicking on Webmin's cachemgr.cgi link creates numerous instances of <emphasis>cachemgr.cgi</emphasis> that quickly consume all available memory and brings the system to its knees. </para><para>Joe Cooper reports this to be caused by SSL problems in some outdated browsers (mainly Netscape 6.x/Mozilla) if your Webmin is SSL enabled. Try with a more current browser or disable SSL encryption in Webmin. </para></section><section><title>Segment Violation at startup or upon first request</title><para>Some versions of GCC (notably 2.95.1 through 2.95.4 at least) have bugs with compiler optimization.  These GCC bugs may cause NULL pointer accesses in Squid, resulting in a &quot;FATAL: Received Segment Violation...dying<emphasis>&quot; message and a core dump. </emphasis> </para></section><section><title>urlParse: Illegal character in hostname 'proxy.mydomain.com:8080proxy.mydomain.com'</title><para>By Yomler of fnac.net </para><para>A combination of a bad configuration of Internet Explorer and any application which use the cydoor DLLs will produce the entry in the log. See <ulink url="http://www.cydoor.com/">cydoor.com</ulink> for a complete list. </para><para>The bad configuration of IE is the use of a active configuration script (proxy.pac) and an active or inactive, but filled proxy settings. IE will only use the proxy.pac. Cydoor aps will use both and will generate the errors. </para><para>Disabling the old proxy settings in IE is not enought, you should delete them completely and only use the proxy.pac for example. </para></section><section><title>Requests for international domain names do not work</title><para>by <ulink url="https://wiki.squid-cache.org/SquidFaq/TroubleShooting/HenrikNordstr%C3%B6m#">HenrikNordström</ulink>. </para><para>Some people have asked why requests for domain names using national symbols as &quot;supported&quot; by the certain domain registrars does not work in Squid. This is because there as of yet is no standard on how to manage national characters in the current Internet protocols such as HTTP or DNS. The current Internet standards is very strict on what is an acceptable hostname and only accepts A-Z a-z 0-9 and - in Internet hostname labels. Anything outside this is outside the current Internet standards and will cause interoperability issues such as the problems seen with such names and Squid. </para><para>When there is a consensus in the DNS and HTTP standardization groups on how to handle international domain names Squid will be changed to support this if any changes to Squid will be required. </para><para>If you are interested in the progress of the standardization process for international domain names please see the IETF IDN working group's <ulink url="http://www.i-d-n.net/">dedicated page</ulink>. </para></section><section><title>Why do I sometimes get &quot;Zero Sized Reply&quot;?</title><para>This happens when Squid makes a TCP connection to an origin server, but for some reason, the connection is closed before Squid reads any data. Depending on various factors, Squid may be able to retry the request again. If you see the &quot;Zero Sized Reply&quot; error message, it means that Squid was unable to retry, or that all retry attempts also failed. </para><para>What causes a connection to close prematurely?  It could be a number of things, including: </para><itemizedlist><listitem><para>An overloaded origin server. </para></listitem><listitem><para>TCP implementation/interoperability bugs. See the <ulink url="https://wiki.squid-cache.org/SquidFaq/TroubleShooting/SquidFaq/SystemWeirdnesses#">../SystemWeirdnesses</ulink> for details. </para></listitem><listitem><para>Race conditions with HTTP persistent connections. </para></listitem><listitem><para>Buggy or misconfigured NAT boxes, firewalls, and load-balancers. </para></listitem><listitem><para>Denial of service attacks. </para></listitem><listitem><para>Utilizing TCP blackholing on FreeBSD (check <ulink url="https://wiki.squid-cache.org/SquidFaq/TroubleShooting/SquidFaq/SystemWeirdnesses#">../SystemWeirdnesses</ulink>). </para></listitem></itemizedlist><para>You may be able to use <emphasis>tcpdump</emphasis> to track down and observe the problem. </para><itemizedlist><listitem override="none"><para><inlinemediaobject><imageobject><imagedata depth="16" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/icon-info.png" width="16"/></imageobject><textobject><phrase>{i}</phrase></textobject></inlinemediaobject> Some users believe the problem is caused by very large cookies. One user reports that his Zero Sized Reply problem went away when he told Internet Explorer to not accept third-party cookies. </para></listitem></itemizedlist><para>Here are some things you can try to reduce the occurance of the Zero Sized Reply error: </para><itemizedlist><listitem><para>Delete or rename your cookie file and configure your browser to prompt you before accepting any new cookies. </para></listitem><listitem><para>Disable HTTP persistent connections with the <emphasis>server_persistent_connections</emphasis> and <emphasis>client_persistent_connections</emphasis> directives. </para></listitem><listitem><para>Disable any advanced TCP features on the Squid system.  Disable ECN on Linux with <emphasis>echo 0 &gt; /proc/sys/net/ipv4/tcp_ecn/</emphasis>. </para></listitem><listitem><para><inlinemediaobject><imageobject><imagedata depth="15" fileref="https://wiki.squid-cache.org/wiki/squidtheme/img/idea.png" width="15"/></imageobject><textobject><phrase>(!)</phrase></textobject></inlinemediaobject> Upgrade to Squid-2.6 or later to work around a Host header related bug in Cisco PIX HTTP inspection. The Cisco PIX firewall wrongly assumes the Host header can be found in the first packet of the request. </para></listitem></itemizedlist><para>If this error causes serious problems for you and the above does not help, Squid developers would be happy to help you uncover the problem.  However, we will require high-quality debugging information from you, such as <emphasis>tcpdump</emphasis> output, server IP addresses, operating system versions, and <emphasis>access.log</emphasis> entries with full HTTP headers. </para><para>If you want to make Squid give the Zero Sized error on demand, you can use <ulink url="https://wiki.squid-cache.org/SquidFaq/TroubleShooting/SquidFaq/TroubleShooting?action=AttachFile&amp;do=get&amp;target=zerosized_reply.c">a short C program</ulink>.  Simply compile and start the program on a system that doesn't already have a server running on port 80.  Then try to connect to this fake server through Squid. </para></section><section><title>Why do I get &quot;The request or reply is too large&quot; errors?</title><para>by Grzegorz Janoszka </para><para>This error message appears when you try downloading large file using GET or uploading it using POST/PUT. There are several parameters to look for: </para><itemizedlist><listitem><para><ulink url="http://www.squid-cache.org/Doc/config/request_body_max_size#">request_body_max_size</ulink> </para></listitem><listitem><para><ulink url="http://www.squid-cache.org/Doc/config/reply_body_max_size#">reply_body_max_size</ulink> </para></listitem></itemizedlist><para>These two are set to 0 by default, which means no limits at all. They should not be limited unless you really know how that affects your squid behavior. Or at all in standard proxy. </para><itemizedlist><listitem><para><ulink url="http://www.squid-cache.org/Doc/config/request_header_max_size#">request_header_max_size</ulink> </para></listitem><listitem><para><ulink url="http://www.squid-cache.org/Doc/config/reply_header_max_size#">reply_header_max_size</ulink> </para></listitem></itemizedlist><para>These two default to 64kB starting from <ulink url="https://wiki.squid-cache.org/SquidFaq/TroubleShooting/Squid-3.1#">Squid-3.1</ulink>. Earlier versions of Squid had defaults as low as 2 kB. In some rather rare circumstances even 64kB is too low, so you can increase this value. </para></section><section><title>Negative or very large numbers in Store Directory Statistics, or constant complaints about cache above limit</title><para>In some situations where swap.state has been corrupted Squid can be very confused about how much data it has in the cache. Such corruption may happen after a power failure or similar fatal event. To recover first stop Squid, then delete the swap.state files from each cache directory and then start Squid again. Squid will automatically rebuild the swap.state index from the cached files reasonably well. </para><para>If this does not work or causes too high load on your server due to the reindexing of the cache then delete the cache content as explained in <ulink url="https://wiki.squid-cache.org/SquidFaq/TroubleShooting/SquidFaq/OperatingSquid#">../OperatingSquid</ulink>. </para></section><section><title>Problems with Windows update</title><itemizedlist><listitem override="none"><para>see <ulink url="https://wiki.squid-cache.org/SquidFaq/TroubleShooting/SquidFaq/WindowsUpdate#">SquidFaq/WindowsUpdate</ulink> </para></listitem></itemizedlist><!--rule (<hr>) is not applicable to DocBook--><para>Back to the <ulink url="https://wiki.squid-cache.org/SquidFaq/TroubleShooting/SquidFaq#">SquidFaq</ulink> </para></section></article>